from pyspark import SparkConf , SparkContext
import pandas as pd

conf= SparkConf().setAppName("similaritywordcount")
sc= SparkContext(conf=conf)

doc1=sc.textFile("sample.txt")
wordCount1=doc1.flatMap(lambda line: line.split(" ")) \
            .map(lambda word: (word,1)) \
            .reduceByKey(lambda a, b : a+b)
commonWordCount = wordCount1
a= commonWordCount.collect()

for i in a:
  print(i)



